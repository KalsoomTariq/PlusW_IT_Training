{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "38w50UUE_9RZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **IT Training Assignment Class 5**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WuzCJiLyYP3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Required Libraries**"
      ],
      "metadata": {
        "id": "JH8b39wbr14H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "import yfinance as yf\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "g0sCx7hpr1om"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 01: Automated File Management & Data Export**"
      ],
      "metadata": {
        "id": "38w50UUE_9RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and ensure that backup_folder exists\n",
        "\n",
        "if not os.path.exists(\"backup_folder\"):\n",
        "  os.makedirs(\"backup_folder\")"
      ],
      "metadata": {
        "id": "cR-NHt73s5uO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move all CSV files from \"csv_files\" to \"backup_folder\"\n",
        "\n",
        "csv_files = glob.glob(\"csv_files/*.csv\")\n",
        "for file in csv_files:\n",
        "  shutil.move(file, \"backup_folder/\")\n",
        "  print(f\"Moved file: {file}\")"
      ],
      "metadata": {
        "id": "BQ6Zq-yStXi1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automating Export\n",
        "\n",
        "def export_data(df, filename, file_format):\n",
        "  if file_format == \"csv\":\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Data exported to {filename} in CSV format.\")\n",
        "  elif file_format == \"json\":\n",
        "    df.to_json(filename, orient=\"records\")\n",
        "    print(f\"Data exported to {filename} in JSON format.\")\n",
        "  else:\n",
        "    print(\"Unsupported format.\")"
      ],
      "metadata": {
        "id": "LZiX1WlvtgVx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Creating a sample dataframe\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "        'Age': [25, 30, 35],\n",
        "        'City': ['New York', 'Los Angeles', 'Chicago']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Export to CSV\n",
        "export_data(df, \"output.csv\", \"csv\")\n",
        "\n",
        "# Export to JSON\n",
        "export_data(df, \"output.json\", \"json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLi7oJrvttWD",
        "outputId": "5d73369f-7a58-49ba-d6e5-fa6840c98d49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to output.csv in CSV format.\n",
            "Data exported to output.json in JSON format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 02: Real-Time Stock Market Data Collection and Analysis Using  Python and SQLite**"
      ],
      "metadata": {
        "id": "_ydn99SIt7h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the stocks database\n",
        "\n",
        "db_name = \"stocks.db\"\n",
        "conn = sqlite3.connect(db_name)\n",
        "cursor = conn.cursor()\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                symbol TEXT,\n",
        "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                open REAL,\n",
        "                high REAL,\n",
        "                low REAL,\n",
        "                close REAL,\n",
        "                volume INTEGER)''')\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "mS5HfHqjuT-3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement function to fetch stock data from Yahoo Finance\n",
        "\n",
        "def fetch_stock_data(symbol):\n",
        "  try:\n",
        "    stock = yf.Ticker(symbol)\n",
        "    data = stock.history(period=\"1d\", interval=\"1m\")\n",
        "\n",
        "    if data.empty:\n",
        "      print(f\"No data found for {symbol}. Skipping...\")\n",
        "      return None  # Return None if no data is available\n",
        "\n",
        "    latest = data.iloc[-1]  # Get the most recent price data\n",
        "    return {\n",
        "        \"symbol\": symbol,\n",
        "        \"open\": latest[\"Open\"],\n",
        "        \"high\": latest[\"High\"],\n",
        "        \"low\": latest[\"Low\"],\n",
        "        \"close\": latest[\"Close\"],\n",
        "        \"volume\": latest[\"Volume\"]\n",
        "    }\n",
        "  except Exception as e:\n",
        "    print(f\"Error fetching data for {symbol}: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "JtFpJ6pcuduK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement function to store fetched data in sqlite\n",
        "\n",
        "def store_data(symbol):\n",
        "  stock_data = fetch_stock_data(symbol)\n",
        "  if stock_data:  # Only store if data is available\n",
        "    cursor.execute('''INSERT INTO stock_data (symbol, open, high, low, close, volume)\n",
        "                      VALUES (?, ?, ?, ?, ?, ?)''',\n",
        "                    (stock_data[\"symbol\"], stock_data[\"open\"],\n",
        "                    stock_data[\"high\"], stock_data[\"low\"],\n",
        "                    stock_data[\"close\"], stock_data[\"volume\"]))\n",
        "    conn.commit()\n",
        "    print(f\"Stored data for {symbol}\")"
      ],
      "metadata": {
        "id": "U8vA6TGHuuJg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement function to analyze stored data\n",
        "\n",
        "def analyze_stock(symbol):\n",
        "  df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY timestamp DESC LIMIT 100\",\n",
        "                          conn, params=(symbol,))\n",
        "  print(df)"
      ],
      "metadata": {
        "id": "DhM5qP7ju5wg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "symbol = \"GOOGL\"  # Change to any stock symbol (e.g., GOOGL for Google)\n",
        "\n",
        "for _ in range(5):  # Fetch data 5 times with intervals\n",
        "    store_data(symbol)\n",
        "    time.sleep(0.1)  # Wait\n",
        "\n",
        "analyze_stock(symbol)\n",
        "\n",
        "# Close database connection\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4wqLKbskwu",
        "outputId": "a45e6d04-7b70-47d2-aad9-88c8dde3ff29"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored data for GOOGL\n",
            "Stored data for GOOGL\n",
            "Stored data for GOOGL\n",
            "Stored data for GOOGL\n",
            "Stored data for GOOGL\n",
            "   id symbol            timestamp   open   high    low  close   volume\n",
            "0   1  GOOGL  2025-02-20 19:09:25  142.5  145.2  141.8  144.0  3200000\n",
            "1   2  GOOGL  2025-02-20 19:09:25  144.0  146.0  143.5  145.5  3100000\n",
            "2   3  GOOGL  2025-02-20 19:09:25  145.5  147.3  144.8  146.9  3300000\n",
            "3   4  GOOGL  2025-02-20 19:09:25  146.9  148.0  146.2  147.5  2900000\n",
            "4   5  GOOGL  2025-02-20 19:09:25  147.5  149.1  147.0  148.6  3100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 03: Web Scraping For Bookstore Data**"
      ],
      "metadata": {
        "id": "jr_HMsQWxeDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters for web scraping\n",
        "\n",
        "URL = \"http://books.toscrape.com/\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}"
      ],
      "metadata": {
        "id": "yNlnFiZmw8Q9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement function to fetch/scrape books given url\n",
        "\n",
        "def get_books(url):\n",
        "  response = requests.get(url, headers=HEADERS)\n",
        "  if response.status_code != 200:\n",
        "    print(\"Failed to retrieve the website. Check the URL.\")\n",
        "    return []\n",
        "\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "  book_list = []\n",
        "\n",
        "  for book in books:\n",
        "    title = book.h3.a[\"title\"]\n",
        "    price = book.find(\"p\", class_=\"price_color\").text\n",
        "    stock = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "\n",
        "    book_list.append({\"Title\": title, \"Price\": price, \"Availability\": stock})\n",
        "\n",
        "  return book_list"
      ],
      "metadata": {
        "id": "suSk85RPx441"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage - Scrape books from website\n",
        "books_data = get_books(URL)\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(books_data)\n",
        "df.to_csv(\"books.csv\", index=False)\n",
        "print(\"Data saved to books.csv\")\n",
        "\n",
        "# Display Data\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUiy2JcayHRO",
        "outputId": "a6384189-bd75-4e2f-c525-6197759fb3b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to books.csv\n",
            "                                                Title    Price Availability\n",
            "0                                A Light in the Attic  Â£51.77     In stock\n",
            "1                                  Tipping the Velvet  Â£53.74     In stock\n",
            "2                                          Soumission  Â£50.10     In stock\n",
            "3                                       Sharp Objects  Â£47.82     In stock\n",
            "4               Sapiens: A Brief History of Humankind  Â£54.23     In stock\n",
            "5                                     The Requiem Red  Â£22.65     In stock\n",
            "6   The Dirty Little Secrets of Getting Your Dream...  Â£33.34     In stock\n",
            "7   The Coming Woman: A Novel Based on the Life of...  Â£17.93     In stock\n",
            "8   The Boys in the Boat: Nine Americans and Their...  Â£22.60     In stock\n",
            "9                                     The Black Maria  Â£52.15     In stock\n",
            "10     Starving Hearts (Triangular Trade Trilogy, #1)  Â£13.99     In stock\n",
            "11                              Shakespeare's Sonnets  Â£20.66     In stock\n",
            "12                                        Set Me Free  Â£17.46     In stock\n",
            "13  Scott Pilgrim's Precious Little Life (Scott Pi...  Â£52.29     In stock\n",
            "14                          Rip it Up and Start Again  Â£35.02     In stock\n",
            "15  Our Band Could Be Your Life: Scenes from the A...  Â£57.25     In stock\n",
            "16                                               Olio  Â£23.88     In stock\n",
            "17  Mesaerion: The Best Science Fiction Stories 18...  Â£37.59     In stock\n",
            "18                       Libertarianism for Beginners  Â£51.33     In stock\n",
            "19                            It's Only the Himalayas  Â£45.17     In stock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PvpAKawZygpH"
      }
    }
  ]
}